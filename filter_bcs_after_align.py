#!/usr/bin/env python


"""
:Author: Ji Research Group/Stanford Genome Technology Center
:Contact: sgreer2@stanford.edu
:Creation date: 24.11.2016
:Description: 
This script counts and filters barcodes in windows
This script requires:
- all of the python packages listed (imported) below
	
Revisions:
None to date
CURRENT VERSION: 1.0
"""

cur_version = 1.0

### LOAD THE NECESSARY PACKAGES ###

import sys
import os
import __main__ as main
import argparse
import ast
import pandas as pd
import pysam
import numpy as np 

pd.options.mode.chained_assignment = None  # default='warn'

MIN_MAPQ = 0
PERF_CIGAR = False


#################################################################
################                                 ################
################        PARSE THE ARGUMENTS      ################
################                                 ################
#################################################################

### ARGPARSE PARSING ###

def usage():
	print "Usage examples:"
	print os.path.basename(main.__file__) + " --help"
	print os.path.basename(main.__file__) + " -bed regions.bed -b longranger.bam -w 1000 -l bc_list.txt"
	sys.exit(0)

def parse_args():
	parser = argparse.ArgumentParser(description = "A Python script for counting and filtering linked-read barcodes")
	parser.add_argument("--usage", help="usage example", dest="usage", action='store_true')
	parser.add_argument("-bed", help="bed file of coordinates (REQUIRED)", dest="bed_in")
	parser.add_argument("-b", help="BAM file for tumor sample generated by longranger (REQUIRED)", dest="bam_in")
	parser.add_argument("-w", help="count window size (default: 1000)", dest="count_wndw_in", default = int(1000))
	parser.add_argument("-r", help="region_size (default:100000)", dest="region_size_in", default = int(100000))
	parser.add_argument("-n", help="num_bcs (default: 20)", dest="num_maps_in", default = int(20))
	parser.add_argument("-c", help="set_cov", dest="set_cov_in")
	parser.add_argument("-bc", help="bc_file", dest="bc_file_in")
	parser.add_argument("-wcov", help="cov_filter_window_size (default: 10000)", dest="bin_size_in", default = int(10000))
	
	parser.add_argument("--version", action='version', version='%(prog)s ' + str(cur_version))
	return parser.parse_args()


if __name__ == '__main__':
	args = parse_args()
	if(args.usage):
		usage()
	if(not args.bam_in):
		print os.path.basename(main.__file__) + " missing a required input file\n"
		usage()
		sys.exit(1)

### SET THE ARGUMENTS ###

bed_file = args.bed_in
bam_file = args.bam_in
small_w_size = int(args.count_wndw_in)
region_size = args.region_size_in
num_maps = args.num_maps_in
set_cov = args.set_cov_in
bc_file = args.bc_file_in
bin_size = float(args.bin_size_in)

if bc_file:
	print "TRUE"
else:
	print "FALSE"

def get_barcode_ids(bam_in, chrom, start, end, min_mapq, perf_cigar):
	bcs = []
	for r in bam_in.fetch(chrom, start, end):
		if r.mapq >= min_mapq and (not(perf_cigar) or (not(r.cigar is None) and len(r.cigar) == 1)):
		#if r.mapq >= min_mapq:
			if r.has_tag("BX"):
				bc_id=r.get_tag("BX")
				bcs.append(bc_id)
				#bcs = list(set(bcs))
	return tuple(list(bcs))

bam_open = pysam.Samfile(bam_file)


if bed_file:
	bed_df = pd.read_table(bed_file, sep="\t")
	bed_df['bcs'] = bed_df.apply(lambda row: get_barcode_ids(bam_open, str(row['chr']), int(row['start']), int(row['end']), MIN_MAPQ, PERF_CIGAR), axis=1)
elif bc_file:
	bed_df = pd.read_table(bc_file, sep="\t")
else:
	print "User must supply either a bed file or a bc file"
	sys.exit()


print bed_df

bc_list = []
bc_list_n = []

for index,row in bed_df.iterrows():

	# Create data frame of 1kb windows
	start = int(row['start'])
	stop = int(row['end'])
	size = int(stop) - int(start)
	window_start = np.arange(start, start+size, small_w_size+1)
	window_end = window_start+small_w_size
	df = pd.DataFrame([window_start, window_end]).transpose()
	df.columns = ['window_start','window_end']
	df['chr'] = str(row['chr'])
	df = df[['chr','window_start','window_end']]
	region_bc_list = list(ast.literal_eval(str(row['bcs'])))
    
	# Make a list of barcodes in each of the 1kb windows
	window_bcs = []
	for i,r in df.iterrows():  
		window_bc_list = get_barcode_ids(bam_open, r['chr'], r['window_start'], r['window_end'], MIN_MAPQ, PERF_CIGAR)
		window_bcs.append(window_bc_list)
        
    # For each SV-specific barcode, count the number of times it occurs in each region
	for bc in region_bc_list:
		df[bc] = [x.count(bc) for x in window_bcs]
    
    # Write output to file
	#df.to_csv(bam_file[0:-3] + str(row['name']) + ".bc_windows.txt", sep="\t", index=False)

	header = df.columns.tolist()
	bc_header = [b for b in header if b not in ["chr","window_start","window_end"]]

	#print bc_header

	#b_keep = []
	info_keep = []

	for b in bc_header:
			#print b
			df_b = df[["chr","window_start","window_end",b]]
			df_b = df_b.loc[df[b]>0]
			first_map = df_b['window_start'].min()
			last_map = df_b['window_end'].max()
			size_hmw = last_map-first_map
			#num_maps = len(df_b.index)
			num_maps_bc = df[b].sum()
			#print num_maps_bc
			if int(num_maps_bc)>int(num_maps):
				#b_keep.append(b)
				info_keep.append([b,first_map,last_map,size_hmw,num_maps_bc])
				#print "TRUE"
				
	#keep_cols = ["chr","window_start","window_end"] + b_keep
	#final_df = df[keep_cols]
	#final_df.to_csv(bam_file[0:-3] + str(row['name']) + ".bc_summ.txt", sep="\t", index=False)

	info_df = pd.DataFrame(info_keep, columns=["bc","first_map","last_map","size","num_maps"])
	info_df.to_csv(bam_file[0:-3] + str(row['name']) + ".bc_counts.txt", sep="\t", index=False)
	
	info_df_bc = info_df[['bc']]
	info_df_bc['bc'] = info_df_bc['bc'].apply(lambda x: str(x).split("-")[0])
	info_df_bc.to_csv(bam_file[0:-3] + str(row['name']) + ".bc_list.txt", sep="\t", index=False, header=False)
	
	bc_list_n.append(info_df_bc)
	
#################################################################################
# If the user wants to apply filtering by coverage, then execute the code below #
#################################################################################


	
	if set_cov:
	
		num_maps=float(num_maps)
		set_cov=float(set_cov)
		#bin_size=float(10000)

		num_bins = int(float(region_size)/bin_size)

		info_df['read_density'] = info_df.apply(lambda row: float(row['num_maps'])/row['size']*1000, axis = 1)

		cov = []

		for j in range(1,101):
			pct = float(j)/100
			bc_df_list = []
			for i in range(1,num_bins+1):
				window_start = (i-1)*bin_size
				window_end = i*bin_size
		
				temp_df = info_df.loc[(info_df['size']>=window_start) & (info_df['size']<window_end) & (info_df['num_maps'] > num_maps)] #num_maps filter here is redundant with above num_maps filter
				if not temp_df.empty:
					temp_rd = np.percentile(temp_df['read_density'], j)
					temp_df_rd = temp_df.loc[temp_df['read_density']<temp_rd]
					bc_df_list.append(temp_df_rd)

			if bc_df_list:	
				bc_merge_df = pd.concat(bc_df_list)
				cov_val = (bc_merge_df['num_maps'].sum())*140/float(region_size)
				cov.append(cov_val)

		if cov: 
			if len(cov)!=100:
				print "why doesn't length equal 100?"
				sys.exit()
			else:
				#print cov
				#print len(cov)
				cov = [abs(float(c)-set_cov) for c in cov]
				pct = [(i+1) for i,x in enumerate(cov) if x == min(cov)]
				#print cov
				#print min(cov)
				#print pct
				pct = pct[0]

				bcs_index = []
				bc_df_list = []

				for i in range(1,num_bins+1):
					window_start = (i-1)*bin_size
					window_end = i*bin_size
	
					temp_df = info_df.loc[(info_df['size']>=window_start) & (info_df['size']<window_end) & (info_df['num_maps'] > num_maps)]

					if not temp_df.empty:
						temp_rd = np.percentile(temp_df['read_density'], pct)
						print window_start
						print window_end
						print temp_rd
						temp_df_rd = temp_df.loc[temp_df['read_density']<temp_rd]
						bc_df_list.append(temp_df_rd)
	
				bc_merge_df = pd.concat(bc_df_list)
				bc_merge_df['bc_mod'] = bc_merge_df['bc'].apply(lambda x: str(x).split('-')[0])
				bc_merge_df.drop_duplicates(inplace=True)

				bc_df = bc_merge_df[['bc_mod']]
				bc_df.drop_duplicates(inplace=True)
				bc_df.to_csv(bam_file[0:-3] + str(row['name']) + ".bc_list.txt", index=False, header=False)	
		
				bc_list.append(bc_df)

if set_cov:
	bc_df = pd.concat(bc_list)
	bc_df.drop_duplicates(inplace=True)
	bc_df.to_csv(bam_file[0:-3] + "merged.bc_list.txt", index=False, header=False)
else:
	bc_df = pd.concat(bc_list_n)
	bc_df.drop_duplicates(inplace=True)
	bc_df.to_csv(bam_file[0:-3] + "merged.bc_list.txt", index=False, header=False)	

#print pct
#print ((bc_merge_df['num_maps'].sum()))*float(140)/100000
#sum(x$num_maps)*140/100000)


